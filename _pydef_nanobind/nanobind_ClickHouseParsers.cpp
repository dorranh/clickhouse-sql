#include <nanobind/nanobind.h>
#include <nanobind/trampoline.h>
#include <nanobind/stl/array.h>
#include <nanobind/stl/string.h>
#include <nanobind/stl/vector.h>
#include <nanobind/stl/optional.h>
#include <nanobind/stl/shared_ptr.h>
#include <nanobind/stl/unique_ptr.h>
#include <nanobind/stl/map.h>
#include <nanobind/stl/tuple.h>
#include <nanobind/ndarray.h>

// #include "DummyLib.h"

// Clickhouse Headers
#include <Parsers/Lexer.h>
#include <Parsers/ParserQuery.h>
// If you need LexerStandalone.h, uncomment this and add the guard below:
// #define _LIBCPP_HIDE_FROM_ABI  // Prevent libc++ operator new from being defined
// #include <Parsers/LexerStandalone.h>


namespace nb = nanobind;

// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  AUTOGENERATED CODE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
// <litgen_glue_code>  // Autogenerated code below! Do not edit!

// </litgen_glue_code> // Autogenerated code end
// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  AUTOGENERATED CODE END !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!


void py_init_module_clickhouse_sql(nb::module_& m)
{
    // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  AUTOGENERATED CODE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
    // <litgen_pydef> // Autogenerated code below! Do not edit!
    ////////////////////    <generated_from:Lexer.h>    ////////////////////

    { // <namespace DB>
        nb::module_ pyNsDB = m.def_submodule("db", "");
        auto pyEnumTokenType =
            nb::enum_<DB::TokenType>(pyNsDB, "TokenType", nb::is_arithmetic(), "")
            ;


        auto pyNsDB_ClassToken =
            nb::class_<DB::Token>
                (pyNsDB, "Token", "")
            .def_rw("type", &DB::Token::type, "")
            .def_ro("begin", &DB::Token::begin, "")
            .def_ro("end", &DB::Token::end, "")
            .def("size",
                &DB::Token::size)
            .def(nb::init<>())
            .def(nb::init<DB::TokenType, const char *, const char *>(),
                nb::arg("type_"), nb::arg("begin_"), nb::arg("end_"))
            .def("is_significant",
                &DB::Token::isSignificant)
            .def("is_error",
                &DB::Token::isError)
            .def("is_end",
                &DB::Token::isEnd)
            ;


        auto pyNsDB_ClassLexer =
            nb::class_<DB::Lexer>
                (pyNsDB, "Lexer", "")
            .def(nb::init<const char *, const char *, size_t>(),
                nb::arg("begin_"), nb::arg("end_"), nb::arg("max_query_size_") = 0)
            .def("next_token",
                &DB::Lexer::nextToken)
            ;
    } // </namespace DB>
    ////////////////////    </generated_from:Lexer.h>    ////////////////////


    ////////////////////    <generated_from:ParserQuery.h>    ////////////////////

    { // <namespace DB>
        nb::module_ pyNsDB = m.def_submodule("db", "");
        auto pyNsDB_ClassParserQuery =
            nb::class_<DB::ParserQuery>
                (pyNsDB, "ParserQuery", "")
            .def(nb::init<const char *, bool, bool>(),
                nb::arg("end_"), nb::arg("allow_settings_after_format_in_insert_") = false, nb::arg("implicit_select_") = false)
            ;
    } // </namespace DB>
    ////////////////////    </generated_from:ParserQuery.h>    ////////////////////

    // </litgen_pydef> // Autogenerated code end
    // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  AUTOGENERATED CODE END !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
}